{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9SFEn0WS_Vg"
   },
   "source": [
    "Step 1. Follow along with the tutorial to gain an understanding of the process<br>\n",
    "Step 2. In a new .ipynb notebook, reproduce the results utilizing the \"QMNIST\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sSXgGCkmTFNm"
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HPh7qjLNS01r",
    "outputId": "6e2160b1-d8dd-4c2d-c5f7-0c69c21f3e69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-train-images-idx3-ubyte.gz to ./data/QMNIST/raw/qmnist-train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9704059/9704059 [00:00<00:00, 305101597.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/QMNIST/raw/qmnist-train-images-idx3-ubyte.gz to ./data/QMNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-train-labels-idx2-int.gz to ./data/QMNIST/raw/qmnist-train-labels-idx2-int.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 463024/463024 [00:00<00:00, 66509021.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/QMNIST/raw/qmnist-train-labels-idx2-int.gz to ./data/QMNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-test-images-idx3-ubyte.gz to ./data/QMNIST/raw/qmnist-test-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9742279/9742279 [00:00<00:00, 236224302.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/QMNIST/raw/qmnist-test-images-idx3-ubyte.gz to ./data/QMNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/facebookresearch/qmnist/master/qmnist-test-labels-idx2-int.gz to ./data/QMNIST/raw/qmnist-test-labels-idx2-int.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 526800/526800 [00:00<00:00, 44937143.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/QMNIST/raw/qmnist-test-labels-idx2-int.gz to ./data/QMNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load \"QMNIST\" dataset and preprocess\n",
    "\n",
    "# transforms.compose is used to chain together mutliple images, using a transformation pipeline  with two transformations\n",
    "# ToTensor is used to convert image to Pytorch tensor, scale pixels to (0.0, 1.0)\n",
    "# Normalizes the tensor by subracting the mean and divinding by sd. Mean and sd are 0.5, 0.5.\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5))])\n",
    "train_dataset = torchvision.datasets.QMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.QMNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5ZgCjF1kYUwM"
   },
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qU9xSXvWYU6f"
   },
   "outputs": [],
   "source": [
    "# show sample information\n",
    "first_sample = train_dataset[0]\n",
    "image, label = first_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "YwhCXOJlYzfm",
    "outputId": "c6b5bf07-10fb-4126-f168-bf2c8686edd6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the PyTorch tensor to a NumPy array\n",
    "image_np = np.transpose(image.numpy(), (1, 2, 0))  # Assuming the image is in shape (C, H, W)\n",
    "\n",
    "# Denormalize the image (reverse the normalization process)\n",
    "image_denormalized = 0.5 * image_np + 0.5\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image_denormalized, cmap='gray')\n",
    "plt.title(f'Label: {label}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14kpvBKl2fxk",
    "outputId": "4371445c-8a4b-499a-d3c2-56a2df33a735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique labels [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "unique_labels = set()\n",
    "\n",
    "for _, label in train_dataset:\n",
    "    unique_labels.add(label)\n",
    "\n",
    "unique_labels_list = list(unique_labels)\n",
    "\n",
    "print(\"unique labels\", unique_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "4nOwt20H1YWk",
    "outputId": "38c06fb1-ac33-4222-b6de-ba2487ae2288"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"0\",\n",
    "    1: \"1\",\n",
    "    2: \"2\",\n",
    "    3: \"3\",\n",
    "    4: \"4\",\n",
    "    5: \"5\",\n",
    "    6: \"6\",\n",
    "    7: \"7\",\n",
    "    8: \"8\",\n",
    "    9: \"9\",\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "# Define grid to show 9 images\n",
    "cols, rows = 3, 3\n",
    "# Iterate\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
    "    img, label = train_dataset[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "z32O_S0vYziW",
    "outputId": "885f3380-4f29-4e9e-96e2-461f5152735f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test DataSet\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(test_dataset), size=(1,)).item()\n",
    "    img, label = test_dataset[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "YjQnYDeXYzll"
   },
   "outputs": [],
   "source": [
    "# Define nn architecture\n",
    "# Define a class MLP which inherits from nn module\n",
    "class MLP(nn.Module):\n",
    "  # Dfine a constructor for MLP class, initialize the layers of nn within\n",
    "    def __init__(self):\n",
    "        # Constructor of parent class using 'super'\n",
    "        super(MLP, self).__init__()\n",
    "        # Creates the first fully connected layer, input size is 28*28 which\n",
    "        # is usually an  images, output size is 128 neurons\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        # Second fully connected layer, with input size of 128 from previous layer\n",
    "        # output size of 64\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        # Third fully connected layer, with input size of 64 neurons\n",
    "        # out is 10, which is inline with the number of classes\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    # Deines a forward pass, how data is processed thru layers\n",
    "    def forward(self, x):\n",
    "        # Reshapes x into 2D sensor. Using -1 as a placeholder, allowing\n",
    "        # Pytorch is automtically infer the size laong that dimension based\n",
    "        x = x.view(-1, 28*28)\n",
    "        # The reshapred input passes thru first fully connected layer, applies\n",
    "        # activation function relu - rectified linear unit to output of fc1\n",
    "        # ReLU introduces non-linearity to model by setting negative values to 0\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        # Same as prior layer\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        # No activation function is applied, raw outputfor each class is obtained\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# initialize the model\n",
    "model = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tRKy5usDDnok",
    "outputId": "cf7b3efe-98db-4f4a-9f6b-7950350ed30c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 0.9621492025256156\n",
      "Epoch 1, Batch 200, Loss: 0.4250109454989433\n",
      "Epoch 1, Batch 300, Loss: 0.38933383390307424\n",
      "Epoch 1, Batch 400, Loss: 0.32502142161130904\n",
      "Epoch 1, Batch 500, Loss: 0.2979604957252741\n",
      "Epoch 1, Batch 600, Loss: 0.2826373122259975\n",
      "Epoch 1, Batch 700, Loss: 0.26712387181818487\n",
      "Epoch 1, Batch 800, Loss: 0.24593285761773587\n",
      "Epoch 1, Batch 900, Loss: 0.21890168339014054\n",
      "Epoch 2, Batch 100, Loss: 0.21867671430110933\n",
      "Epoch 2, Batch 200, Loss: 0.18625396728515625\n",
      "Epoch 2, Batch 300, Loss: 0.18763508938252926\n",
      "Epoch 2, Batch 400, Loss: 0.18168044362217187\n",
      "Epoch 2, Batch 500, Loss: 0.1785512656532228\n",
      "Epoch 2, Batch 600, Loss: 0.15849911753088236\n",
      "Epoch 2, Batch 700, Loss: 0.16774379801005124\n",
      "Epoch 2, Batch 800, Loss: 0.15447987835854293\n",
      "Epoch 2, Batch 900, Loss: 0.16136079641059042\n",
      "Epoch 3, Batch 100, Loss: 0.13200416451320052\n",
      "Epoch 3, Batch 200, Loss: 0.12798839880153537\n",
      "Epoch 3, Batch 300, Loss: 0.1274131123907864\n",
      "Epoch 3, Batch 400, Loss: 0.13130060549825429\n",
      "Epoch 3, Batch 500, Loss: 0.14636310156434773\n",
      "Epoch 3, Batch 600, Loss: 0.1283192151412368\n",
      "Epoch 3, Batch 700, Loss: 0.13004343344829977\n",
      "Epoch 3, Batch 800, Loss: 0.12501881519332528\n",
      "Epoch 3, Batch 900, Loss: 0.12277726056054235\n",
      "Epoch 4, Batch 100, Loss: 0.10881900696083903\n",
      "Epoch 4, Batch 200, Loss: 0.10264080697670579\n",
      "Epoch 4, Batch 300, Loss: 0.09774093205109238\n",
      "Epoch 4, Batch 400, Loss: 0.09921634647063911\n",
      "Epoch 4, Batch 500, Loss: 0.1151038749748841\n",
      "Epoch 4, Batch 600, Loss: 0.10356098894029855\n",
      "Epoch 4, Batch 700, Loss: 0.10768870433792471\n",
      "Epoch 4, Batch 800, Loss: 0.11647361271083355\n",
      "Epoch 4, Batch 900, Loss: 0.09771448995918036\n",
      "Epoch 5, Batch 100, Loss: 0.08043960543349385\n",
      "Epoch 5, Batch 200, Loss: 0.09812830447219312\n",
      "Epoch 5, Batch 300, Loss: 0.09840827196836471\n",
      "Epoch 5, Batch 400, Loss: 0.07911165621131659\n",
      "Epoch 5, Batch 500, Loss: 0.09126512583345175\n",
      "Epoch 5, Batch 600, Loss: 0.08399192985147237\n",
      "Epoch 5, Batch 700, Loss: 0.10110424258746206\n",
      "Epoch 5, Batch 800, Loss: 0.08797988008707762\n",
      "Epoch 5, Batch 900, Loss: 0.0911344890575856\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "# this is multiclass classificiation task\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Define Adam optimizer which is commonly used for nn,\n",
    "# takes parameter of model and lr\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train nn\n",
    "# Define number of iterations, which is 5 over entire training ds\n",
    "num_epochs = 5\n",
    "# loop thru\n",
    "for epoch in range(num_epochs):\n",
    "    # Sets the training model\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    # Iterates over batches\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        # clears tge gradient before backward pass\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass obtained from model predictions\n",
    "        outputs = model(inputs)\n",
    "        # computes loss between actual and predicted labels\n",
    "        loss = criterion(outputs, labels)\n",
    "        # backward pass to computer gradients of loss with respect\n",
    "        # to model parameters\n",
    "        loss.backward()\n",
    "        # update model parameters\n",
    "        optimizer.step()\n",
    "        # # accumulates the running loss\n",
    "        running_loss += loss.item()\n",
    "        # print for every 100 batches\n",
    "        if i % 100 == 99:\n",
    "            print(f'Epoch {epoch+1}, Batch {i+1}, Loss: {running_loss/100}')\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzrGQZPdTqb0"
   },
   "source": [
    "Step 3. Report on the results in terms of prediction accuracy on the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C7UgjqtLS8MH",
    "outputId": "35f3a1ca-1cc0-4ec0-a543-edcffd4d122f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 0.9243166666666667%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on train dataset\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on train set: { correct / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_TJnoVaDnrw",
    "outputId": "6b316070-e28a-4863-c3ed-4b3118038346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set : 0.96515\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# Set model to eval mode, important as certain layers behave differently\n",
    "# during training and eval mode. This ensures layers are working preoperly during eval mode\n",
    "model.eval()\n",
    "# number of correctly predicted samples\n",
    "correct = 0\n",
    "# total number of samples in test dataset\n",
    "total = 0\n",
    "# disable gradient during eval, to reduce memory consumption and\n",
    "# speed up computations\n",
    "with torch.no_grad():\n",
    "    # loop thru test data\n",
    "    for data in test_loader:\n",
    "      images, labels = data\n",
    "      # forward pass to obtain predictions\n",
    "      outputs = model(images)\n",
    "      # Finds the index of max value aling second dimension to determin\n",
    "      # predicted value\n",
    "      # find number of correctley predicted and adds to correct var\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      # adds total no of samples in current batch\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "\n",
    "# prints the accuracy on test\n",
    "print(f'Accuracy on test set : {correct/total}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRncyoS97APD"
   },
   "source": [
    "The train accuracy is at 0.924.\n",
    "The test  accuracy is at 0.965."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jk5YIIJ660D8"
   },
   "source": [
    "Step 4. Choose one of the proposed modifications below:\n",
    "Increase the current number of nodes in the layer to 256\n",
    "\n",
    "Step 5. Modify the model based on the chosen method and train\n",
    "\n",
    "Step 6. Report on the results of the modified model and if it matches your hypothesis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MyUtt6fr6uU7",
    "outputId": "0419aacd-1f7a-4ab2-8250-ae8001a2e450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 0.9121754357218742\n",
      "Epoch 1, Batch 200, Loss: 0.43478208139538765\n",
      "Epoch 1, Batch 300, Loss: 0.3699024184048176\n",
      "Epoch 1, Batch 400, Loss: 0.3431335014104843\n",
      "Epoch 1, Batch 500, Loss: 0.30324044190347194\n",
      "Epoch 1, Batch 600, Loss: 0.2831197682768106\n",
      "Epoch 1, Batch 700, Loss: 0.24392057254910468\n",
      "Epoch 1, Batch 800, Loss: 0.2294036802649498\n",
      "Epoch 1, Batch 900, Loss: 0.20788953974843025\n",
      "Epoch 2, Batch 100, Loss: 0.19591262124478817\n",
      "Epoch 2, Batch 200, Loss: 0.20683618776500226\n",
      "Epoch 2, Batch 300, Loss: 0.16954208739101886\n",
      "Epoch 2, Batch 400, Loss: 0.17468042325228453\n",
      "Epoch 2, Batch 500, Loss: 0.16386450193822383\n",
      "Epoch 2, Batch 600, Loss: 0.169181207716465\n",
      "Epoch 2, Batch 700, Loss: 0.15062157412990929\n",
      "Epoch 2, Batch 800, Loss: 0.1406803495064378\n",
      "Epoch 2, Batch 900, Loss: 0.13658329878002406\n",
      "Epoch 3, Batch 100, Loss: 0.13506511420011522\n",
      "Epoch 3, Batch 200, Loss: 0.11988122407346964\n",
      "Epoch 3, Batch 300, Loss: 0.10798973420634866\n",
      "Epoch 3, Batch 400, Loss: 0.11310415137559175\n",
      "Epoch 3, Batch 500, Loss: 0.12747455531731247\n",
      "Epoch 3, Batch 600, Loss: 0.13299152337014675\n",
      "Epoch 3, Batch 700, Loss: 0.11353567434474826\n",
      "Epoch 3, Batch 800, Loss: 0.10545335851609706\n",
      "Epoch 3, Batch 900, Loss: 0.12804106962867082\n",
      "Epoch 4, Batch 100, Loss: 0.08864727446809412\n",
      "Epoch 4, Batch 200, Loss: 0.09811335825361311\n",
      "Epoch 4, Batch 300, Loss: 0.10314075053669512\n",
      "Epoch 4, Batch 400, Loss: 0.10293789641931653\n",
      "Epoch 4, Batch 500, Loss: 0.10698519358411432\n",
      "Epoch 4, Batch 600, Loss: 0.10531775302253664\n",
      "Epoch 4, Batch 700, Loss: 0.1037556052301079\n",
      "Epoch 4, Batch 800, Loss: 0.09653455007821321\n",
      "Epoch 4, Batch 900, Loss: 0.09426892780698835\n",
      "Epoch 5, Batch 100, Loss: 0.0704474973725155\n",
      "Epoch 5, Batch 200, Loss: 0.08030534098157659\n",
      "Epoch 5, Batch 300, Loss: 0.07277496952097863\n",
      "Epoch 5, Batch 400, Loss: 0.07693100583739579\n",
      "Epoch 5, Batch 500, Loss: 0.08231728321872651\n",
      "Epoch 5, Batch 600, Loss: 0.08574456005357206\n",
      "Epoch 5, Batch 700, Loss: 0.08603770918212832\n",
      "Epoch 5, Batch 800, Loss: 0.08662593185901642\n",
      "Epoch 5, Batch 900, Loss: 0.09302121018990875\n",
      "Finished Training\n",
      "Accuracy on train set : 0.97655\n",
      "Accuracy on test set: 0.9662666666666667\n"
     ]
    }
   ],
   "source": [
    "#Define the neural network architecture\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the neural network\n",
    "model = MLP()\n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the neural network\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # print every 100 mini-batches\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Evaluate the model on train\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on train set : { correct / total}')\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model on test\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on test set: { correct / total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPHeZw5M9J03"
   },
   "source": [
    "Upon increasing the number of neurons from 128 to 256 in one of the hidden layer, the accuracy changed on the train dataset but decreased on the test dataset.\n",
    "\n",
    "**With 2 hidden layers, 128 neurons**:\n",
    "The train accuracy is at 0.924.\n",
    "The test  accuracy is at 0.965.\n",
    "\n",
    "**With 2 hidden layers, 256 neurons**:\n",
    "The train accuracy is at 0.977.\n",
    "The test  accuracy is at 0.966.\n",
    "\n",
    "**HYPOTHESIS**:\n",
    "Both the configurations have a good generalization with accuracies over 90%. The second configuration with 256 neurons in the hidden layer performed better on the training dataset, not much of a difference on the test dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXYVDuK3_KiV"
   },
   "source": [
    "Step 7. Experiment with different optimizers, loss functions, dropout, and activation functions, and observe the change in performance as you tune these hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VUxOQ0vC_F3b",
    "outputId": "9b59e545-09d5-4ad0-dfaf-cc83739eb670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 2.3046752548217775\n",
      "Epoch 1, Batch 200, Loss: 2.288102676868439\n",
      "Epoch 1, Batch 300, Loss: 2.267842319011688\n",
      "Epoch 1, Batch 400, Loss: 2.2471624398231507\n",
      "Epoch 1, Batch 500, Loss: 2.23373486995697\n",
      "Epoch 1, Batch 600, Loss: 2.2156960225105284\n",
      "Epoch 1, Batch 700, Loss: 2.1958187794685364\n",
      "Epoch 1, Batch 800, Loss: 2.1717891573905943\n",
      "Epoch 1, Batch 900, Loss: 2.1482464814186097\n",
      "Epoch 2, Batch 100, Loss: 2.1111663508415224\n",
      "Epoch 2, Batch 200, Loss: 2.0847871994972227\n",
      "Epoch 2, Batch 300, Loss: 2.0596769297122957\n",
      "Epoch 2, Batch 400, Loss: 2.0200118696689606\n",
      "Epoch 2, Batch 500, Loss: 1.9829500067234038\n",
      "Epoch 2, Batch 600, Loss: 1.947284438610077\n",
      "Epoch 2, Batch 700, Loss: 1.9046822798252105\n",
      "Epoch 2, Batch 800, Loss: 1.8542744302749634\n",
      "Epoch 2, Batch 900, Loss: 1.7978544735908508\n",
      "Epoch 3, Batch 100, Loss: 1.7336861753463746\n",
      "Epoch 3, Batch 200, Loss: 1.6850206005573272\n",
      "Epoch 3, Batch 300, Loss: 1.6198584961891174\n",
      "Epoch 3, Batch 400, Loss: 1.5701846921443938\n",
      "Epoch 3, Batch 500, Loss: 1.5072678923606873\n",
      "Epoch 3, Batch 600, Loss: 1.456992553472519\n",
      "Epoch 3, Batch 700, Loss: 1.3907849860191346\n",
      "Epoch 3, Batch 800, Loss: 1.3476501846313476\n",
      "Epoch 3, Batch 900, Loss: 1.2786131179332734\n",
      "Epoch 4, Batch 100, Loss: 1.2112953436374665\n",
      "Epoch 4, Batch 200, Loss: 1.183648083806038\n",
      "Epoch 4, Batch 300, Loss: 1.131031070947647\n",
      "Epoch 4, Batch 400, Loss: 1.078268719315529\n",
      "Epoch 4, Batch 500, Loss: 1.0444604080915452\n",
      "Epoch 4, Batch 600, Loss: 0.9943444842100143\n",
      "Epoch 4, Batch 700, Loss: 0.9822027111053466\n",
      "Epoch 4, Batch 800, Loss: 0.9344510453939437\n",
      "Epoch 4, Batch 900, Loss: 0.9156558030843734\n",
      "Epoch 5, Batch 100, Loss: 0.8729759120941162\n",
      "Epoch 5, Batch 200, Loss: 0.8424442881345748\n",
      "Epoch 5, Batch 300, Loss: 0.8139429134130478\n",
      "Epoch 5, Batch 400, Loss: 0.8064605879783631\n",
      "Epoch 5, Batch 500, Loss: 0.7795319825410842\n",
      "Epoch 5, Batch 600, Loss: 0.7580591988563538\n",
      "Epoch 5, Batch 700, Loss: 0.7319425165653228\n",
      "Epoch 5, Batch 800, Loss: 0.7289941954612732\n",
      "Epoch 5, Batch 900, Loss: 0.6952117323875427\n",
      "Time taken to complete training with optimizer SGD, 256 neurons in hidden layer: 95.894676 seconds\n",
      "Finished Training\n",
      "Accuracy on train set with optimizer SGD, 256 neurons in hidden layer: 0.834667\n",
      "Accuracy on test set with optimizer SGD, 256 neurons in hidden layer: 0.835250\n"
     ]
    }
   ],
   "source": [
    "# Experiment 1, with optimzer SGD, lr=0.001, relu activation\n",
    "# See how long it take for SGD optimizer\n",
    "import time\n",
    "#Define the neural network architecture\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the neural network\n",
    "model = MLP()\n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the neural network\n",
    "# record start time\n",
    "start_time = time.time()\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # print every 100 mini-batches\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
    "            running_loss = 0.0\n",
    "# record end time\n",
    "end_time = time.time()\n",
    "# Calculate elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f'Time taken to complete training with optimizer SGD, 256 neurons in hidden layer: {elapsed_time:4f} seconds')\n",
    "print('Finished Training')\n",
    "\n",
    "# Evaluate the model on train\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'# Experiment 1, Accuracy on train set with optimizer SGD, 256 neurons in hidden layer: { correct / total:3f}')\n",
    "\n",
    "# Evaluate the model on test\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'# Experiment 1, Accuracy on test set with optimizer SGD, 256 neurons in hidden layer: { correct / total:3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8FCO8b39Ghy7",
    "outputId": "0f02f7e3-5ea3-4514-b672-294759c87104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 2.2067065954208376\n",
      "Epoch 1, Batch 200, Loss: 1.876954070329666\n",
      "Epoch 1, Batch 300, Loss: 1.3531356644630432\n",
      "Epoch 1, Batch 400, Loss: 0.9505016154050827\n",
      "Epoch 1, Batch 500, Loss: 0.7400380736589431\n",
      "Epoch 1, Batch 600, Loss: 0.6260212323069573\n",
      "Epoch 1, Batch 700, Loss: 0.552189191877842\n",
      "Epoch 1, Batch 800, Loss: 0.5071370193362236\n",
      "Epoch 1, Batch 900, Loss: 0.4740216141939163\n",
      "Epoch 2, Batch 100, Loss: 0.4333972644805908\n",
      "Epoch 2, Batch 200, Loss: 0.4151847732067108\n",
      "Epoch 2, Batch 300, Loss: 0.3962256141006947\n",
      "Epoch 2, Batch 400, Loss: 0.3914231026172638\n",
      "Epoch 2, Batch 500, Loss: 0.36755448326468465\n",
      "Epoch 2, Batch 600, Loss: 0.3610346783697605\n",
      "Epoch 2, Batch 700, Loss: 0.35333085283637045\n",
      "Epoch 2, Batch 800, Loss: 0.3528887727111578\n",
      "Epoch 2, Batch 900, Loss: 0.351417283564806\n",
      "Epoch 3, Batch 100, Loss: 0.3334797301143408\n",
      "Epoch 3, Batch 200, Loss: 0.31704793266952036\n",
      "Epoch 3, Batch 300, Loss: 0.31657054349780084\n",
      "Epoch 3, Batch 400, Loss: 0.31606059700250627\n",
      "Epoch 3, Batch 500, Loss: 0.3232582399249077\n",
      "Epoch 3, Batch 600, Loss: 0.3268173822015524\n",
      "Epoch 3, Batch 700, Loss: 0.3061617536097765\n",
      "Epoch 3, Batch 800, Loss: 0.3279367381334305\n",
      "Epoch 3, Batch 900, Loss: 0.3058359391242266\n",
      "Epoch 4, Batch 100, Loss: 0.2879314787685871\n",
      "Epoch 4, Batch 200, Loss: 0.28260808542370797\n",
      "Epoch 4, Batch 300, Loss: 0.28050610452890395\n",
      "Epoch 4, Batch 400, Loss: 0.29007245905697343\n",
      "Epoch 4, Batch 500, Loss: 0.2763784511387348\n",
      "Epoch 4, Batch 600, Loss: 0.2994120668619871\n",
      "Epoch 4, Batch 700, Loss: 0.2915808768570423\n",
      "Epoch 4, Batch 800, Loss: 0.27254547640681265\n",
      "Epoch 4, Batch 900, Loss: 0.2892065892368555\n",
      "Epoch 5, Batch 100, Loss: 0.26050062358379367\n",
      "Epoch 5, Batch 200, Loss: 0.2634263576567173\n",
      "Epoch 5, Batch 300, Loss: 0.2657261949032545\n",
      "Epoch 5, Batch 400, Loss: 0.24505599401891232\n",
      "Epoch 5, Batch 500, Loss: 0.24799104556441307\n",
      "Epoch 5, Batch 600, Loss: 0.26730641528964044\n",
      "Epoch 5, Batch 700, Loss: 0.2636806443706155\n",
      "Epoch 5, Batch 800, Loss: 0.2513331350684166\n",
      "Epoch 5, Batch 900, Loss: 0.2598711124807596\n",
      "Time taken to complete training with optimizer SGD, 256 neurons in hidden layer: 79.772410 seconds\n",
      "Finished Training\n",
      "# Experiment 2, Accuracy on train set with optimizer SGD, 256 neurons in hidden layer: 0.928133\n",
      "# Experiment 2, Accuracy on test set with optimizer SGD, 256 neurons in hidden layer: 0.925283\n"
     ]
    }
   ],
   "source": [
    "# Experiment 2, with optimzer SGD, lr=0.01,relu activation\n",
    "\n",
    "# See how long it take for SGD optimizer\n",
    "import time\n",
    "#Define the neural network architecture\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the neural network\n",
    "model = MLP()\n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the neural network\n",
    "# record start time\n",
    "start_time = time.time()\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # print every 100 mini-batches\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
    "            running_loss = 0.0\n",
    "# record end time\n",
    "end_time = time.time()\n",
    "# Calculate elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f'Time taken to complete training with optimizer SGD, 256 neurons in hidden layer: {elapsed_time:4f} seconds')\n",
    "print('Finished Training')\n",
    "\n",
    "# Evaluate the model on train\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'# Experiment 2, Accuracy on train set with optimizer SGD, 256 neurons in hidden layer: { correct / total:3f}')\n",
    "\n",
    "# Evaluate the model on test\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'# Experiment 2, Accuracy on test set with optimizer SGD, 256 neurons in hidden layer: { correct / total:3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLhjzsZQ_F7N",
    "outputId": "acbaac80-5612-4dee-cb76-818b8b563d62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 2.331490650177002\n",
      "Epoch 1, Batch 200, Loss: 2.3221409821510317\n",
      "Epoch 1, Batch 300, Loss: 2.3150864601135255\n",
      "Epoch 1, Batch 400, Loss: 2.3133491539955138\n",
      "Epoch 1, Batch 500, Loss: 2.3091562271118162\n",
      "Epoch 1, Batch 600, Loss: 2.305357439517975\n",
      "Epoch 1, Batch 700, Loss: 2.30480087518692\n",
      "Epoch 1, Batch 800, Loss: 2.3006588554382326\n",
      "Epoch 1, Batch 900, Loss: 2.3014282393455505\n",
      "Epoch 2, Batch 100, Loss: 2.3002705216407775\n",
      "Epoch 2, Batch 200, Loss: 2.2997730660438536\n",
      "Epoch 2, Batch 300, Loss: 2.2997936677932738\n",
      "Epoch 2, Batch 400, Loss: 2.2991098976135254\n",
      "Epoch 2, Batch 500, Loss: 2.299192850589752\n",
      "Epoch 2, Batch 600, Loss: 2.299509904384613\n",
      "Epoch 2, Batch 700, Loss: 2.298721635341644\n",
      "Epoch 2, Batch 800, Loss: 2.2978901648521424\n",
      "Epoch 2, Batch 900, Loss: 2.2981412053108214\n",
      "Epoch 3, Batch 100, Loss: 2.2973610019683837\n",
      "Epoch 3, Batch 200, Loss: 2.2982091546058654\n",
      "Epoch 3, Batch 300, Loss: 2.29792555809021\n",
      "Epoch 3, Batch 400, Loss: 2.2975367665290833\n",
      "Epoch 3, Batch 500, Loss: 2.29604008436203\n",
      "Epoch 3, Batch 600, Loss: 2.296190264225006\n",
      "Epoch 3, Batch 700, Loss: 2.295764763355255\n",
      "Epoch 3, Batch 800, Loss: 2.2960554552078247\n",
      "Epoch 3, Batch 900, Loss: 2.2960257148742675\n",
      "Epoch 4, Batch 100, Loss: 2.295586426258087\n",
      "Epoch 4, Batch 200, Loss: 2.2956962323188783\n",
      "Epoch 4, Batch 300, Loss: 2.2941310596466065\n",
      "Epoch 4, Batch 400, Loss: 2.2940078926086427\n",
      "Epoch 4, Batch 500, Loss: 2.2947143268585206\n",
      "Epoch 4, Batch 600, Loss: 2.2940765237808227\n",
      "Epoch 4, Batch 700, Loss: 2.2941673135757448\n",
      "Epoch 4, Batch 800, Loss: 2.294455523490906\n",
      "Epoch 4, Batch 900, Loss: 2.2946136522293092\n",
      "Epoch 5, Batch 100, Loss: 2.292826533317566\n",
      "Epoch 5, Batch 200, Loss: 2.2934769201278686\n",
      "Epoch 5, Batch 300, Loss: 2.292539803981781\n",
      "Epoch 5, Batch 400, Loss: 2.292975571155548\n",
      "Epoch 5, Batch 500, Loss: 2.2915362977981566\n",
      "Epoch 5, Batch 600, Loss: 2.291531009674072\n",
      "Epoch 5, Batch 700, Loss: 2.2923837065696717\n",
      "Epoch 5, Batch 800, Loss: 2.2934407377243042\n",
      "Epoch 5, Batch 900, Loss: 2.291094706058502\n",
      "Time taken to complete training with optimizer SGD, 256 neurons in hidden layer: 87.100694 seconds\n",
      "Finished Training\n",
      "# Experiment 3, Accuracy on train set with optimizer SGD, 256 neurons in hidden layer: 0.112367\n",
      "# Experiment 3, Accuracy on test set with optimizer SGD, 256 neurons in hidden layer: 0.113183\n"
     ]
    }
   ],
   "source": [
    "# Experiment 3, with optimzer SGD, lr=0.001, Sigmoid activation\n",
    "# See how long it take for SGD optimizer\n",
    "import time\n",
    "#Define the neural network architecture\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the neural network\n",
    "model = MLP()\n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the neural network\n",
    "# record start time\n",
    "start_time = time.time()\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # print every 100 mini-batches\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
    "            running_loss = 0.0\n",
    "# record end time\n",
    "end_time = time.time()\n",
    "# Calculate elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f'Time taken to complete training with optimizer SGD, 256 neurons in hidden layer: {elapsed_time:4f} seconds')\n",
    "print('Finished Training')\n",
    "\n",
    "# Evaluate the model on train\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'# Experiment 3, Accuracy on train set with optimizer SGD, 256 neurons in hidden layer: { correct / total:3f}')\n",
    "\n",
    "# Evaluate the model on test\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'# Experiment 3, Accuracy on test set with optimizer SGD, 256 neurons in hidden layer: { correct / total:3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aupTj7wQ6uc2",
    "outputId": "2bee921c-8583-44cc-99fe-2baf97c09ce3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 2.317882363796234\n",
      "Epoch 1, Batch 200, Loss: 2.2998710918426513\n",
      "Epoch 1, Batch 300, Loss: 2.296475350856781\n",
      "Epoch 1, Batch 400, Loss: 2.2943694853782652\n",
      "Epoch 1, Batch 500, Loss: 2.2911573386192323\n",
      "Epoch 1, Batch 600, Loss: 2.289230082035065\n",
      "Epoch 1, Batch 700, Loss: 2.2865749287605284\n",
      "Epoch 1, Batch 800, Loss: 2.2834078955650328\n",
      "Epoch 1, Batch 900, Loss: 2.28136878490448\n",
      "Epoch 2, Batch 100, Loss: 2.2772333788871766\n",
      "Epoch 2, Batch 200, Loss: 2.271771824359894\n",
      "Epoch 2, Batch 300, Loss: 2.2689205956459046\n",
      "Epoch 2, Batch 400, Loss: 2.264391310214996\n",
      "Epoch 2, Batch 500, Loss: 2.2610004854202272\n",
      "Epoch 2, Batch 600, Loss: 2.2554412341117858\n",
      "Epoch 2, Batch 700, Loss: 2.2487022566795347\n",
      "Epoch 2, Batch 800, Loss: 2.2429858231544495\n",
      "Epoch 2, Batch 900, Loss: 2.234431893825531\n",
      "Epoch 3, Batch 100, Loss: 2.2227804255485535\n",
      "Epoch 3, Batch 200, Loss: 2.209872488975525\n",
      "Epoch 3, Batch 300, Loss: 2.20202431678772\n",
      "Epoch 3, Batch 400, Loss: 2.1826230478286743\n",
      "Epoch 3, Batch 500, Loss: 2.169681980609894\n",
      "Epoch 3, Batch 600, Loss: 2.1465751338005066\n",
      "Epoch 3, Batch 700, Loss: 2.127248213291168\n",
      "Epoch 3, Batch 800, Loss: 2.1046522426605225\n",
      "Epoch 3, Batch 900, Loss: 2.0801301646232604\n",
      "Epoch 4, Batch 100, Loss: 2.0300558376312257\n",
      "Epoch 4, Batch 200, Loss: 2.01041851401329\n",
      "Epoch 4, Batch 300, Loss: 1.96434720993042\n",
      "Epoch 4, Batch 400, Loss: 1.914210604429245\n",
      "Epoch 4, Batch 500, Loss: 1.8769102132320403\n",
      "Epoch 4, Batch 600, Loss: 1.841085798740387\n",
      "Epoch 4, Batch 700, Loss: 1.8033911991119385\n",
      "Epoch 4, Batch 800, Loss: 1.7474863409996033\n",
      "Epoch 4, Batch 900, Loss: 1.7131016743183136\n",
      "Epoch 5, Batch 100, Loss: 1.6390568780899049\n",
      "Epoch 5, Batch 200, Loss: 1.5924455118179321\n",
      "Epoch 5, Batch 300, Loss: 1.5363440942764282\n",
      "Epoch 5, Batch 400, Loss: 1.4937633061408997\n",
      "Epoch 5, Batch 500, Loss: 1.4670581388473511\n",
      "Epoch 5, Batch 600, Loss: 1.4113729727268218\n",
      "Epoch 5, Batch 700, Loss: 1.3768308401107787\n",
      "Epoch 5, Batch 800, Loss: 1.3248331940174103\n",
      "Epoch 5, Batch 900, Loss: 1.2904359030723571\n",
      "Time taken to complete training with optimizer SGD, 256 neurons in hidden layer: 93.245087 seconds\n",
      "Finished Training\n",
      "# Experiment 4, Accuracy on train set with optimizer SGD, 256 neurons in hidden layer: 0.662200\n",
      "# Experiment 4, Accuracy on test set with optimizer SGD, 256 neurons in hidden layer: 0.663633\n"
     ]
    }
   ],
   "source": [
    "# Experiment 4, with optimzer SGD, lr=0.01, Sigmoid activation\n",
    "# See how long it take for SGD optimizer\n",
    "import time\n",
    "#Define the neural network architecture\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the neural network\n",
    "model = MLP()\n",
    "\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the neural network\n",
    "# record start time\n",
    "start_time = time.time()\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # print every 100 mini-batches\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
    "            running_loss = 0.0\n",
    "# record end time\n",
    "end_time = time.time()\n",
    "# Calculate elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f'Time taken to complete training with optimizer SGD, 256 neurons in hidden layer: {elapsed_time:4f} seconds')\n",
    "print('Finished Training')\n",
    "\n",
    "# Evaluate the model on train\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'# Experiment 4, Accuracy on train set with optimizer SGD, 256 neurons in hidden layer: { correct / total:3f}')\n",
    "\n",
    "# Evaluate the model on test\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'# Experiment 4, Accuracy on test set with optimizer SGD, 256 neurons in hidden layer: { correct / total:3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9a13eUDH8se"
   },
   "source": [
    "FINAL RESULTS:\n",
    "\n",
    "\n",
    "Experiment 1  (optimzer SGD, lr=0.001, relu activation:\n",
    "Time taken to complete training with optimizer SGD, 256 neurons in hidden layer: 95.894676 seconds\n",
    "Finished Training\n",
    "Accuracy on train set with optimizer SGD, 256 neurons in hidden layer: 0.834667\n",
    "Accuracy on test set with optimizer SGD, 256 neurons in hidden layer: 0.835250\n",
    "\n",
    "Experiment 2 (optimzer SGD, lr=0.01, relu activation):\n",
    "Time taken to complete training with optimizer SGD, 256 neurons in hidden layer: 79.772410 seconds\n",
    "Finished Training\n",
    "Experiment 2, Accuracy on train set with optimizer SGD, 256 neurons in hidden layer: 0.928133\n",
    "Experiment 2, Accuracy on test set with optimizer SGD, 256 neurons in hidden layer: 0.925283\n",
    "\n",
    "**Incase of experiment 1 and 2, having optimzer SGD, relu activation, but different learning rates of 0.001 and 0.01 shows that Experiment 2 performed better than Experiement 1 in terms of accuracy as weil las the time taken to complete training. The experiment shows the model is able to generalize better with a learning rate of 0.01, implying the model performs better at lower learning rate.**\n",
    "\n",
    " Experiment 3 (optimzer SGD, lr=0.001, Sigmoid activation):\n",
    " Time taken to complete training with optimizer SGD, 256 neurons in hidden layer: 87.100694 seconds\n",
    "Finished Training\n",
    "Experiment 3, Accuracy on train set with optimizer SGD, 256 neurons in hidden layer: 0.112367\n",
    "Experiment 3, Accuracy on test set with optimizer SGD, 256 neurons in hidden layer: 0.113183\n",
    "\n",
    "Experiment 4(optimzer SGD, lr=0.01, Sigmoid activation):\n",
    "Time taken to complete training with optimizer SGD, 256 neurons in hidden layer: 93.245087 seconds\n",
    "Finished Training\n",
    "Experiment 4, Accuracy on train set with optimizer SGD, 256 neurons in hidden layer: 0.662200\n",
    "Experiment 4, Accuracy on test set with optimizer SGD, 256 neurons in hidden layer: 0.663633\n",
    "\n",
    "**Incase of experiment 3 and 4, having optimzer SGD, Sigmoid activation, but different learning rates of 0.001 and 0.01 shows that experiment 3 has a very poor accuracy on train and test dataset(0.1133 and 0.113) as compared to 0.662 and 0.663 maybe the model converges very slowly and may not reach the optimal solution. Experiment 3 may also be stuck in local minima, leading to poor convergence. The model may underfit the data leading to the very low accuracy. Experiement 3 took 87 seconds to complete the training and Experiment 4 took 93 seconds. In case of experiemtn 3 and 4, the learning rate of 0.01 appears to be more suitable with a slightly better accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R6FWFTDoIAKL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
