{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPCZ1YkmU9c1UsBr4r3Ps0p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b4d0c9eeda714c46b3bf961327b5b5a7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_222457077da243cba9019fae7d4617d9","IPY_MODEL_80b8395e1b1b4217969a966f54f3e015","IPY_MODEL_c653d5f26c0941a290a493902fcc2ea2"],"layout":"IPY_MODEL_3e769d3e37d1409aad87f030bde19267"}},"222457077da243cba9019fae7d4617d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6d7f5b7d6d549ab982baa27f3f42160","placeholder":"​","style":"IPY_MODEL_02fba9b1673b4d5e97a28575ee9b580c","value":"Training: 100%"}},"80b8395e1b1b4217969a966f54f3e015":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_8135347ab34d48349b4ecce2ecf52325","max":157,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0e025b869d934d9b9861e3119c9ee2c7","value":157}},"c653d5f26c0941a290a493902fcc2ea2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68dff1bab74047878a1702d23422b7be","placeholder":"​","style":"IPY_MODEL_160a0b11a71b4a07bb485881b762c8ab","value":" 157/157 [01:57&lt;00:00,  1.36it/s]"}},"3e769d3e37d1409aad87f030bde19267":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"c6d7f5b7d6d549ab982baa27f3f42160":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02fba9b1673b4d5e97a28575ee9b580c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8135347ab34d48349b4ecce2ecf52325":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e025b869d934d9b9861e3119c9ee2c7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"68dff1bab74047878a1702d23422b7be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"160a0b11a71b4a07bb485881b762c8ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4200a88df83b4159af14957047a069ac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_219be9e557d0494cbe01bf7c080bfdb9","IPY_MODEL_c8dc17282a284ca587ae64270af4c12a","IPY_MODEL_d3c17f0bac6e4eedbe85c2eaa2248f4c"],"layout":"IPY_MODEL_714d6e32b804452fb5aac485b5bcc25d"}},"219be9e557d0494cbe01bf7c080bfdb9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b905ca43eeae43dc94689831c1d9ce32","placeholder":"​","style":"IPY_MODEL_063d6c75e7bf4be0bd4a82d7d0f0db90","value":"Validating: 100%"}},"c8dc17282a284ca587ae64270af4c12a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c51e1b2cc27a4bd7ab13f027e5735aae","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27463880d510444a91bed053f25a7d03","value":20}},"d3c17f0bac6e4eedbe85c2eaa2248f4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f947979c0c9647ea9550bf9d00089e7f","placeholder":"​","style":"IPY_MODEL_b45c2cb4a7ff44b19759a851b3ab97ee","value":" 20/20 [00:05&lt;00:00,  4.48it/s]"}},"714d6e32b804452fb5aac485b5bcc25d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"b905ca43eeae43dc94689831c1d9ce32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"063d6c75e7bf4be0bd4a82d7d0f0db90":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c51e1b2cc27a4bd7ab13f027e5735aae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27463880d510444a91bed053f25a7d03":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f947979c0c9647ea9550bf9d00089e7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b45c2cb4a7ff44b19759a851b3ab97ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa028637e0f54e07bd5178b26d0c29a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d12e8da2fc348a18be64bd2341705c5","IPY_MODEL_f8c611e25d274980868280a7ec0067ec","IPY_MODEL_c4f99b9542b44fc9b40d1e868e8bf7f0"],"layout":"IPY_MODEL_a79ea484728a4339925f372fa069c422"}},"5d12e8da2fc348a18be64bd2341705c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1309fb0c17d24be8981b88fe1373acf5","placeholder":"​","style":"IPY_MODEL_c9334f459e2840b1b61309019d1f0a5c","value":"Training: 100%"}},"f8c611e25d274980868280a7ec0067ec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2a38361213141ccb1efaae61c42351c","max":157,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d230a38de604a769da0cc30bc549444","value":157}},"c4f99b9542b44fc9b40d1e868e8bf7f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_610cbef3381549d4bbcf0fdead2d94e2","placeholder":"​","style":"IPY_MODEL_38fa42c32db74139ab01641a01ddab77","value":" 157/157 [02:03&lt;00:00,  1.46it/s]"}},"a79ea484728a4339925f372fa069c422":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"1309fb0c17d24be8981b88fe1373acf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9334f459e2840b1b61309019d1f0a5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2a38361213141ccb1efaae61c42351c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d230a38de604a769da0cc30bc549444":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"610cbef3381549d4bbcf0fdead2d94e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38fa42c32db74139ab01641a01ddab77":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b6f68e2365f4f88a535391977a4655a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6f6928ebe344119a062decac05eae5c","IPY_MODEL_7a78f4b3054649fda12a6ddeaf1fe4b6","IPY_MODEL_7d78fdeaa76045c7bc65c507a9b8aec0"],"layout":"IPY_MODEL_5de646ab48f644c3829409782c1e30d9"}},"d6f6928ebe344119a062decac05eae5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87cbba1e9964422cb740b02c0578b31b","placeholder":"​","style":"IPY_MODEL_e963fa5fb7bb47acb5fe9df9dec70629","value":"Validating: 100%"}},"7a78f4b3054649fda12a6ddeaf1fe4b6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5581fe59216e4c5e841f0bf02c029217","max":20,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4f97c8ddf34f4a758ee10323372cc4a1","value":20}},"7d78fdeaa76045c7bc65c507a9b8aec0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e44515955d494739bb7854cf587e87d4","placeholder":"​","style":"IPY_MODEL_a055e6fb8ce24a49832f81d90158c324","value":" 20/20 [00:05&lt;00:00,  4.55it/s]"}},"5de646ab48f644c3829409782c1e30d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"87cbba1e9964422cb740b02c0578b31b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e963fa5fb7bb47acb5fe9df9dec70629":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5581fe59216e4c5e841f0bf02c029217":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f97c8ddf34f4a758ee10323372cc4a1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e44515955d494739bb7854cf587e87d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a055e6fb8ce24a49832f81d90158c324":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JSzDb1kqqqOh","executionInfo":{"status":"ok","timestamp":1713537074883,"user_tz":420,"elapsed":23143,"user":{"displayName":"Vani Kancherlapalli","userId":"08080360983994426120"}},"outputId":"97bf6204-111d-470b-c5ca-e3c85981d607"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd '/content/drive/My Drive/Data 255 Spring 2024/Google Colab/Homework10'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F-VhMK7Pr6su","executionInfo":{"status":"ok","timestamp":1713537086447,"user_tz":420,"elapsed":1179,"user":{"displayName":"Vani Kancherlapalli","userId":"08080360983994426120"}},"outputId":"478a0c49-6bfe-4999-d005-609f350a8edd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Data 255 Spring 2024/Google Colab/Homework9\n"]}]},{"cell_type":"code","source":["!pip install pytorch_pretrained_bert"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bzNlKxkNr6xN","executionInfo":{"status":"ok","timestamp":1713537169101,"user_tz":420,"elapsed":81208,"user":{"displayName":"Vani Kancherlapalli","userId":"08080360983994426120"}},"outputId":"f31ef105-4f0b-432e-99a1-0b04c8bdad21"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch_pretrained_bert\n","  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/123.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2.2.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (1.25.2)\n","Collecting boto3 (from pytorch_pretrained_bert)\n","  Downloading boto3-1.34.87-py3-none-any.whl (139 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (4.66.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_bert) (2023.12.25)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=0.4.1->pytorch_pretrained_bert)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=0.4.1->pytorch_pretrained_bert)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=0.4.1->pytorch_pretrained_bert)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=0.4.1->pytorch_pretrained_bert)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=0.4.1->pytorch_pretrained_bert)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=0.4.1->pytorch_pretrained_bert)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=0.4.1->pytorch_pretrained_bert)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=0.4.1->pytorch_pretrained_bert)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=0.4.1->pytorch_pretrained_bert)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch>=0.4.1->pytorch_pretrained_bert)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=0.4.1->pytorch_pretrained_bert)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=0.4.1->pytorch_pretrained_bert)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Collecting botocore<1.35.0,>=1.34.87 (from boto3->pytorch_pretrained_bert)\n","  Downloading botocore-1.34.87-py3-none-any.whl (12.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch_pretrained_bert)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->pytorch_pretrained_bert)\n","  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch_pretrained_bert) (2024.2.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.87->boto3->pytorch_pretrained_bert) (2.8.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->pytorch_pretrained_bert) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->pytorch_pretrained_bert) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.87->boto3->pytorch_pretrained_bert) (1.16.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, nvidia-cusparse-cu12, nvidia-cudnn-cu12, botocore, s3transfer, nvidia-cusolver-cu12, boto3, pytorch_pretrained_bert\n","Successfully installed boto3-1.34.87 botocore-1.34.87 jmespath-1.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pytorch_pretrained_bert-0.6.2 s3transfer-0.10.1\n"]}]},{"cell_type":"code","source":["# private model that provides underlying implementations for linear algebra\n","import numpy.linalg._umath_linalg\n","print(numpy.linalg._umath_linalg.__file__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kf6u_kcvsJ_s","executionInfo":{"status":"ok","timestamp":1713537249953,"user_tz":420,"elapsed":4,"user":{"displayName":"Vani Kancherlapalli","userId":"08080360983994426120"}},"outputId":"2bbc15db-0ab2-4481-a97a-4fa199d6abd7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.10/dist-packages/numpy/linalg/_umath_linalg.cpython-310-x86_64-linux-gnu.so\n"]}]},{"cell_type":"code","source":["%matplotlib inline\n","%config InlineBackend.figure_formats = ['svg']\n","\n","import random\n","import sys\n","from pathlib import Path\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import regex as re\n","#from pymagnitude import Magnitude\n","from collections.abc import MutableMapping\n","from pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification, BertAdam\n","from sklearn.metrics import classification_report\n","from tqdm import tqdm, tqdm_notebook\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch import optim\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","from torch.utils.data import Dataset, DataLoader, Subset\n","from torch.utils.data.dataset import random_split\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","from IPython.core.display import display, HTML\n","from google_drive_downloader import GoogleDriveDownloader as gdd\n","\n","tqdm.pandas()\n","\n","# If the machine you run this on has a GPU available with CUDA installed,\n","# use it. Using a GPU for learning often leads to huge speedups in training.\n","# See https://developer.nvidia.com/cuda-downloads for installing CUDA\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FyfmhCzfsKC7","executionInfo":{"status":"ok","timestamp":1713537255963,"user_tz":420,"elapsed":4128,"user":{"displayName":"Vani Kancherlapalli","userId":"08080360983994426120"}},"outputId":"f66e4d86-54ee-4535-85dc-440d249f36b0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["DATA_PATH = 'data/imdb_reviews.csv'\n","if not Path(DATA_PATH).is_file():\n","    gdd.download_file_from_google_drive(\n","        file_id='1zfM5E6HvKIe7f3rEt1V2gBpw5QOSSKQz',\n","        dest_path=DATA_PATH,\n","    )"],"metadata":{"id":"IwdQkfqPsKGc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ImdbSentimentDataset(Dataset):\n","    def __init__(self, data_path, max_len):\n","        # Read the dataset from the given CSV file path\n","        df = pd.read_csv(DATA_PATH)\n","\n","        # Initialize BERT tokenizer from the 'bert-base-uncased' pretrained model\n","        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","        # Tokenize the reviews using the BERT tokenizer and limit the tokenized text to max_len - 2 tokens\n","        df['tokenized_text'] = df.review.progress_apply(self.tokenizer.tokenize)\n","\n","        # Shorten to max length (Bert has a limit of 512); subtract two tokens for [CLS] and [SEP]\n","        df.loc[:, 'tokenized_text'] = df.tokenized_text.str[:max_len - 2]\n","\n","        # Add Bert-specific beginning and end tokens\n","        df.loc[:, 'tokenized_text'] = df.tokenized_text.apply(\n","            lambda tokens: ['[CLS]'] + tokens + ['[SEP]'],\n","        )\n","\n","        # Convert tokenized text into indexed tokens\n","        df['indexed_tokens'] = df.tokenized_text.progress_apply(\n","            self.tokenizer.convert_tokens_to_ids,\n","        )\n","\n","        # Prepare sequences, attention masks, and segment IDs\n","        sequences = df.indexed_tokens.tolist()\n","        max_sequence_length = max(len(x) for x in sequences)\n","\n","        self.inputs_lst, self.masks, self.segments = [], [], []\n","        for sequence in sequences:\n","            self.inputs_lst.append(sequence + (max_sequence_length - len(sequence)) * [0])\n","            self.masks.append(len(sequence) * [1] + (max_sequence_length - len(sequence)) * [0])\n","            self.segments.append(max_sequence_length * [0])\n","\n","        # Store targets (labels) and texts (reviews)\n","        self.targets = df.label.tolist()\n","        self.texts = df.review.tolist()\n","\n","    def __getitem__(self, i):\n","        # Return the indexed tokens, attention masks, and segment IDs\n","        return self.inputs_lst[i], self.masks[i], self.segments[i], self.targets[i], self.texts[i]\n","\n","    def __len__(self):\n","        # Return the length of the dataset\n","        return len(self.inputs_lst)"],"metadata":{"id":"9K99-jJKsKJc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# How many tokens long each sequence will be cut to\n","# Shorter sequences will get the padding token <PAD>\n","max_len = 128  #@param {type:\"slider\", min:16, max:512, step:2}\n","\n","dataset = ImdbSentimentDataset(DATA_PATH, max_len)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HBLMKjQvtnPu","executionInfo":{"status":"ok","timestamp":1713537565070,"user_tz":420,"elapsed":266984,"user":{"displayName":"Vani Kancherlapalli","userId":"08080360983994426120"}},"outputId":"8fa7bfbe-6a30-4a58-82b2-d261cc3e1529"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 231508/231508 [00:00<00:00, 883047.50B/s]\n","100%|██████████| 62155/62155 [04:16<00:00, 242.34it/s]\n","100%|██████████| 62155/62155 [00:01<00:00, 38988.06it/s]\n"]}]},{"cell_type":"code","source":["len(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iEwFyqabtuP3","executionInfo":{"status":"ok","timestamp":1713537616781,"user_tz":420,"elapsed":268,"user":{"displayName":"Vani Kancherlapalli","userId":"08080360983994426120"}},"outputId":"a62c1e77-dd84-4256-cbd1-ec1ab76c4c1f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["62155"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["#@title Splitting up the data\n","\n","def split_train_valid_test(corpus, valid_ratio=0.1, test_ratio=0.1):\n","    \"\"\"Split dataset into train, validation, and test.\"\"\"\n","    test_length = int(len(corpus) * valid_ratio)\n","    valid_length = int(len(corpus) * test_ratio)\n","    train_length = len(corpus) - valid_length - test_length\n","    return random_split(\n","        corpus, lengths=[train_length, valid_length, test_length],\n","    )\n","\n","valid_ratio = 0.01  #@param {type:\"slider\", min:0.01, max:0.3, step:0.01}\n","test_ratio = 0.01  #@param {type:\"slider\", min:0.01, max:0.3, step:0.01}\n","\n","# Train on only a subset of the data to reduce training time\n","n_samples = 5000  #@param {type:\"integer\"}\n","\n","train_dataset, valid_dataset, test_dataset = split_train_valid_test(\n","    dataset,\n","    valid_ratio,\n","    test_ratio,\n",")\n","train_dataset = Subset(train_dataset, torch.randperm(len(train_dataset))[:n_samples])\n","len(train_dataset), len(valid_dataset), len(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t7MySySituTq","executionInfo":{"status":"ok","timestamp":1713537618253,"user_tz":420,"elapsed":4,"user":{"displayName":"Vani Kancherlapalli","userId":"08080360983994426120"}},"outputId":"6b1897bb-5838-4055-930e-f2a6943390d0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5000, 621, 621)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["#@title How many examples to load on the GPU at once\n","\n","def collate(batch):\n","    inputs = torch.LongTensor([item[0] for item in batch])\n","    mask = torch.LongTensor([item[1] for item in batch])\n","    segment = torch.LongTensor([item[2] for item in batch])\n","    target = torch.LongTensor([item[3] for item in batch])\n","    text = [item[4] for item in batch]\n","\n","    inputs, mask, segment, target = map(\n","        lambda x: x.to(device),\n","        (inputs, mask, segment, target),\n","    )\n","\n","    return inputs, mask, segment, target, text\n","\n","batch_size = 32  #@param {type:\"integer\"}\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate)\n","valid_loader = DataLoader(valid_dataset, batch_size=batch_size, collate_fn=collate)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate)"],"metadata":{"id":"KPSBwWNwtuXh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title How big of steps the model takes while learning\n","\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n","model = model.to(device)\n","\n","learning_rate = 0.001  #@param {type:\"number\"}\n","\n","param_optimizer = list(model.classifier.named_parameters())\n","optimizer_grouped_parameters = [{'params': [p for n, p in param_optimizer]}]\n","optimizer = BertAdam(optimizer_grouped_parameters, lr=learning_rate)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DYsQhHHrvBjY","executionInfo":{"status":"ok","timestamp":1713537655510,"user_tz":420,"elapsed":26287,"user":{"displayName":"Vani Kancherlapalli","userId":"08080360983994426120"}},"outputId":"b7db7842-d65e-41f6-96f5-5af909911438"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 407873900/407873900 [00:14<00:00, 27960496.13B/s]\n","WARNING:pytorch_pretrained_bert.optimization:t_total value of -1 results in schedule not being applied\n"]}]},{"cell_type":"code","source":["def train_epoch(model, optimizer, train_loader):\n","    model.train()\n","    train_loss = total = 0\n","    for inputs, mask, segment, target, text in tqdm_notebook(train_loader,\n","                                                             desc='Training',\n","                                                             leave=False):\n","        optimizer.zero_grad()\n","\n","        loss = model(inputs, segment, mask, target)\n","\n","        train_loss += loss.item()\n","        total += 1\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    return train_loss / total\n","\n","\n","def validate_epoch(model, valid_loader):\n","    model.eval()\n","    with torch.no_grad():\n","        valid_loss = total = 0\n","        for inputs, mask, segment, target, text in tqdm_notebook(valid_loader,\n","                                                                 desc='Validating',\n","                                                                 leave=False):\n","            loss = model(inputs, segment, mask, target)\n","\n","            valid_loss += loss.item()\n","            total += 1\n","\n","        return valid_loss / total"],"metadata":{"id":"Zyds3KtrvBmq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Limit the number of training epochs (training is slow)\n","\n","max_epochs = 2  #@param {type:\"slider\", min:1, max:10}\n","\n","n_epochs = 0\n","train_losses, valid_losses = [], []\n","while True:\n","    train_loss = train_epoch(model, optimizer, train_loader)\n","    valid_loss = validate_epoch(model, valid_loader)\n","\n","    tqdm.write(\n","        f'epoch #{n_epochs + 1:3d}\\ttrain_loss: {train_loss:.3f}\\tvalid_loss: {valid_loss:.3f}\\n',\n","    )\n","\n","    # Early stopping if the current valid_loss is\n","    # greater than the last three valid losses\n","    if len(valid_losses) > 2 and all(valid_loss > loss for loss in valid_losses[-3:]):\n","        print('Stopping early')\n","        break\n","\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","\n","    n_epochs += 1\n","\n","    if n_epochs >= max_epochs:\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":305,"referenced_widgets":["b4d0c9eeda714c46b3bf961327b5b5a7","222457077da243cba9019fae7d4617d9","80b8395e1b1b4217969a966f54f3e015","c653d5f26c0941a290a493902fcc2ea2","3e769d3e37d1409aad87f030bde19267","c6d7f5b7d6d549ab982baa27f3f42160","02fba9b1673b4d5e97a28575ee9b580c","8135347ab34d48349b4ecce2ecf52325","0e025b869d934d9b9861e3119c9ee2c7","68dff1bab74047878a1702d23422b7be","160a0b11a71b4a07bb485881b762c8ab","4200a88df83b4159af14957047a069ac","219be9e557d0494cbe01bf7c080bfdb9","c8dc17282a284ca587ae64270af4c12a","d3c17f0bac6e4eedbe85c2eaa2248f4c","714d6e32b804452fb5aac485b5bcc25d","b905ca43eeae43dc94689831c1d9ce32","063d6c75e7bf4be0bd4a82d7d0f0db90","c51e1b2cc27a4bd7ab13f027e5735aae","27463880d510444a91bed053f25a7d03","f947979c0c9647ea9550bf9d00089e7f","b45c2cb4a7ff44b19759a851b3ab97ee","fa028637e0f54e07bd5178b26d0c29a8","5d12e8da2fc348a18be64bd2341705c5","f8c611e25d274980868280a7ec0067ec","c4f99b9542b44fc9b40d1e868e8bf7f0","a79ea484728a4339925f372fa069c422","1309fb0c17d24be8981b88fe1373acf5","c9334f459e2840b1b61309019d1f0a5c","f2a38361213141ccb1efaae61c42351c","7d230a38de604a769da0cc30bc549444","610cbef3381549d4bbcf0fdead2d94e2","38fa42c32db74139ab01641a01ddab77","8b6f68e2365f4f88a535391977a4655a","d6f6928ebe344119a062decac05eae5c","7a78f4b3054649fda12a6ddeaf1fe4b6","7d78fdeaa76045c7bc65c507a9b8aec0","5de646ab48f644c3829409782c1e30d9","87cbba1e9964422cb740b02c0578b31b","e963fa5fb7bb47acb5fe9df9dec70629","5581fe59216e4c5e841f0bf02c029217","4f97c8ddf34f4a758ee10323372cc4a1","e44515955d494739bb7854cf587e87d4","a055e6fb8ce24a49832f81d90158c324"]},"id":"peqYP8gRvBqU","executionInfo":{"status":"ok","timestamp":1713537929511,"user_tz":420,"elapsed":251479,"user":{"displayName":"Vani Kancherlapalli","userId":"08080360983994426120"}},"outputId":"ed834f88-927b-4dde-8fc7-6369e0313f1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-14-6161870d6bb6>:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for inputs, mask, segment, target, text in tqdm_notebook(train_loader,\n"]},{"output_type":"display_data","data":{"text/plain":["Training:   0%|          | 0/157 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4d0c9eeda714c46b3bf961327b5b5a7"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1630.)\n","  next_m.mul_(beta1).add_(1 - beta1, grad)\n","<ipython-input-14-6161870d6bb6>:24: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for inputs, mask, segment, target, text in tqdm_notebook(valid_loader,\n"]},{"output_type":"display_data","data":{"text/plain":["Validating:   0%|          | 0/20 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4200a88df83b4159af14957047a069ac"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["epoch #  1\ttrain_loss: 0.691\tvalid_loss: 0.554\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Training:   0%|          | 0/157 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa028637e0f54e07bd5178b26d0c29a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Validating:   0%|          | 0/20 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b6f68e2365f4f88a535391977a4655a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["epoch #  2\ttrain_loss: 0.589\tvalid_loss: 0.525\n","\n"]}]},{"cell_type":"code","source":["epoch_ticks = range(1, n_epochs + 1)\n","plt.plot(epoch_ticks, train_losses)\n","plt.plot(epoch_ticks, valid_losses)\n","plt.legend(['Train Loss', 'Valid Loss'])\n","plt.title('Losses')\n","plt.xlabel('Epoch #')\n","plt.ylabel('Loss')\n","plt.xticks(epoch_ticks)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":456},"id":"97pBwhE202nn","executionInfo":{"status":"ok","timestamp":1713538038997,"user_tz":420,"elapsed":1788,"user":{"displayName":"Vani Kancherlapalli","userId":"08080360983994426120"}},"outputId":"2ac70d03-e892-4ac5-cb7c-4d585effba26"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/svg+xml":"<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"420.82625pt\" height=\"325.986375pt\" viewBox=\"0 0 420.82625 325.986375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2024-04-19T14:47:18.035025</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 325.986375 \nL 420.82625 325.986375 \nL 420.82625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 56.50625 288.430125 \nL 413.62625 288.430125 \nL 413.62625 22.318125 \nL 56.50625 22.318125 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"mec89071c38\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mec89071c38\" x=\"72.738977\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 1 -->\n      <g transform=\"translate(69.557727 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#mec89071c38\" x=\"397.393523\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(394.212273 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_3\">\n     <!-- Epoch # -->\n     <g transform=\"translate(213.976406 316.706687) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-23\" d=\"M 3272 2816 \nL 2363 2816 \nL 2100 1772 \nL 3016 1772 \nL 3272 2816 \nz\nM 2803 4594 \nL 2478 3297 \nL 3391 3297 \nL 3719 4594 \nL 4219 4594 \nL 3897 3297 \nL 4872 3297 \nL 4872 2816 \nL 3775 2816 \nL 3519 1772 \nL 4513 1772 \nL 4513 1294 \nL 3397 1294 \nL 3072 0 \nL 2572 0 \nL 2894 1294 \nL 1978 1294 \nL 1656 0 \nL 1153 0 \nL 1478 1294 \nL 494 1294 \nL 494 1772 \nL 1594 1772 \nL 1856 2816 \nL 850 2816 \nL 850 3297 \nL 1978 3297 \nL 2297 4594 \nL 2803 4594 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"306.201172\"/>\n      <use xlink:href=\"#DejaVuSans-23\" x=\"337.988281\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_3\">\n      <defs>\n       <path id=\"mb7eaab91dc\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mb7eaab91dc\" x=\"56.50625\" y=\"276.132944\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.525 -->\n      <g transform=\"translate(20.878125 279.932163) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"159.033203\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"222.65625\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#mb7eaab91dc\" x=\"56.50625\" y=\"239.729038\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.550 -->\n      <g transform=\"translate(20.878125 243.528257) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"222.65625\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#mb7eaab91dc\" x=\"56.50625\" y=\"203.325133\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.575 -->\n      <g transform=\"translate(20.878125 207.124351) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"159.033203\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"222.65625\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#mb7eaab91dc\" x=\"56.50625\" y=\"166.921227\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.600 -->\n      <g transform=\"translate(20.878125 170.720446) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"222.65625\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#mb7eaab91dc\" x=\"56.50625\" y=\"130.517321\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.625 -->\n      <g transform=\"translate(20.878125 134.31654) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"159.033203\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"222.65625\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#mb7eaab91dc\" x=\"56.50625\" y=\"94.113416\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.650 -->\n      <g transform=\"translate(20.878125 97.912634) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"222.65625\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#mb7eaab91dc\" x=\"56.50625\" y=\"57.70951\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.675 -->\n      <g transform=\"translate(20.878125 61.508729) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"159.033203\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"222.65625\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_11\">\n     <!-- Loss -->\n     <g transform=\"translate(14.798438 166.341312) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-4c\" d=\"M 628 4666 \nL 1259 4666 \nL 1259 531 \nL 3531 531 \nL 3531 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-4c\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"53.962891\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"115.144531\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"167.244141\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_10\">\n    <path d=\"M 72.738977 34.414125 \nL 397.393523 183.208519 \n\" clip-path=\"url(#pa509f00294)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_11\">\n    <path d=\"M 72.738977 234.122 \nL 397.393523 276.334125 \n\" clip-path=\"url(#pa509f00294)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 56.50625 288.430125 \nL 56.50625 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 413.62625 288.430125 \nL 413.62625 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 56.50625 288.430125 \nL 413.62625 288.430125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 56.50625 22.318125 \nL 413.62625 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_12\">\n    <!-- Losses -->\n    <g transform=\"translate(215.088125 16.318125) scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-4c\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"53.962891\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"115.144531\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"167.244141\"/>\n     <use xlink:href=\"#DejaVuSans-65\" x=\"219.34375\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"280.867188\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 325.415313 59.674375 \nL 406.62625 59.674375 \nQ 408.62625 59.674375 408.62625 57.674375 \nL 408.62625 29.318125 \nQ 408.62625 27.318125 406.62625 27.318125 \nL 325.415313 27.318125 \nQ 323.415313 27.318125 323.415313 29.318125 \nL 323.415313 57.674375 \nQ 323.415313 59.674375 325.415313 59.674375 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_12\">\n     <path d=\"M 327.415313 35.416562 \nL 337.415313 35.416562 \nL 347.415313 35.416562 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_13\">\n     <!-- Train Loss -->\n     <g transform=\"translate(355.415313 38.916562) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-54\" d=\"M -19 4666 \nL 3928 4666 \nL 3928 4134 \nL 2272 4134 \nL 2272 0 \nL 1638 0 \nL 1638 4134 \nL -19 4134 \nL -19 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-54\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"239.888672\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"271.675781\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"325.638672\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"386.820312\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"438.919922\"/>\n     </g>\n    </g>\n    <g id=\"line2d_13\">\n     <path d=\"M 327.415313 50.094687 \nL 337.415313 50.094687 \nL 347.415313 50.094687 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_14\">\n     <!-- Valid Loss -->\n     <g transform=\"translate(355.415313 53.594687) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-56\" d=\"M 1831 0 \nL 50 4666 \nL 709 4666 \nL 2188 738 \nL 3669 4666 \nL 4325 4666 \nL 2547 0 \nL 1831 0 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-56\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"60.658203\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"121.9375\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"149.720703\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"177.503906\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"240.980469\"/>\n      <use xlink:href=\"#DejaVuSans-4c\" x=\"272.767578\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"326.730469\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"387.912109\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"440.011719\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pa509f00294\">\n   <rect x=\"56.50625\" y=\"22.318125\" width=\"357.12\" height=\"266.112\"/>\n  </clipPath>\n </defs>\n</svg>\n"},"metadata":{}}]},{"cell_type":"code","source":["model.eval()\n","y_true, y_pred = [], []\n","with torch.no_grad():\n","    for inputs, mask, segment, target, text in test_loader:\n","        loss = model(inputs, segment, mask, target)\n","        logits = model(inputs, segment, mask)\n","\n","        logits = logits.detach().cpu().numpy()\n","        predictions = np.argmax(logits, axis=1)\n","        target = target.cpu().numpy()\n","\n","        y_true.extend(predictions)\n","        y_pred.extend(target)\n","\n","print(classification_report(y_true, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bpD_9ZbE02ow","executionInfo":{"status":"ok","timestamp":1713538060601,"user_tz":420,"elapsed":10899,"user":{"displayName":"Vani Kancherlapalli","userId":"08080360983994426120"}},"outputId":"4b5ce2b4-81d7-4776-a87c-283ce3833fd1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.69      0.71      0.70       299\n","           1       0.73      0.71      0.72       322\n","\n","    accuracy                           0.71       621\n","   macro avg       0.71      0.71      0.71       621\n","weighted avg       0.71      0.71      0.71       621\n","\n"]}]},{"cell_type":"code","source":["flatten = lambda x: [sublst for lst in x for sublst in lst]\n","inputs_lst, mask_lst, segment_lst, target_lst, text_lst = zip(*test_loader)\n","inputs_lst, mask_lst, segment_lst, target_lst, text_lst = map(flatten, [inputs_lst, mask_lst, segment_lst, target_lst, text_lst])\n","test_examples = list(zip(inputs_lst, mask_lst, segment_lst, target_lst, text_lst))\n","\n","def print_random_prediction(n=10):\n","    to_emoji = lambda x: '😄' if x else '😡'\n","    model.eval()\n","    rows = []\n","    for _ in range(n):\n","        with torch.no_grad():\n","            inputs, target, segment, target, text = random.choice(test_examples)\n","\n","            logits = model(inputs.unsqueeze(0))\n","            logits = logits.detach().cpu().numpy()\n","            prediction = np.argmax(logits, axis=1)[0]\n","\n","            predicted = to_emoji(prediction)\n","            actual = to_emoji(target)\n","\n","            row = f\"\"\"\n","            <tr>\n","            <td>{text}&nbsp;</td>\n","            <td>{predicted}&nbsp;</td>\n","            <td>{actual}&nbsp;</td>\n","            </tr>\n","            \"\"\"\n","            rows.append(row)\n","\n","    rows_joined = '\\n'.join(rows)\n","    table = f\"\"\"\n","<table>\n","<tbody>\n","<tr>\n","<td><b>Review</b>&nbsp;</td>\n","<td><b>Predicted</b>&nbsp;</td>\n","<td><b>Actual</b>&nbsp;</td>\n","</tr>\n","{rows_joined}\n","</tbody>\n","</table>\n","\"\"\"\n","    display(HTML(table))"],"metadata":{"id":"NVhuHboY1CRe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_random_prediction(n=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"wBu5xjx81Gds","executionInfo":{"status":"ok","timestamp":1713538102369,"user_tz":420,"elapsed":912,"user":{"displayName":"Vani Kancherlapalli","userId":"08080360983994426120"}},"outputId":"78be93f1-f60c-4073-df9c-60715ba73215"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<table>\n","<tbody>\n","<tr>\n","<td><b>Review</b>&nbsp;</td>\n","<td><b>Predicted</b>&nbsp;</td>\n","<td><b>Actual</b>&nbsp;</td>\n","</tr>\n","\n","            <tr>\n","            <td>The films use of blue-black and vibrant skin tones to create a noir-ish feel to this movie unfortunately do not work. In fact its quite irritating as it obscures the demon characters and reduces them to one dimensional beings.<br /><br />At least the original had an hysterical energy and the gore set-pieces were quite stunning. Black gore is hardly frightening, nor is the main female demon at all frightening in her attempts to snarl and growl at the screen in her best camp Lugosi style.<br /><br />The narrative is grossly disjointed and if you could imagine 'Naked Lunch' directed by Russ Meyer you may appreciate the attempt to be William Burroughs-esque. Otherwise give this film a wide girth. Bava and Argento fans - once again - are bitterly disappointed.&nbsp;</td>\n","            <td>😡&nbsp;</td>\n","            <td>😡&nbsp;</td>\n","            </tr>\n","            \n","\n","            <tr>\n","            <td>Seth McFarlane is a true genius. He has crafted a show that is witty, culturally sharp and just downright hilarious.<br /><br />For those that think its 'offensive' take on social or cultural topics makes no meaningful comment, just causes 'offence', can be pointed to this quote:<br /><br />Peter (coming out of the stem cell lab): How long was I in there? // Guard: Five minutes. // Peter: Why aren't we funding this?!?<br /><br />Why indeed.<br /><br />Thanks family guy, for being not only the funniest show on TV (with the possible exception of the much loved, much missed futurama), but for also being pretty clever to boot.&nbsp;</td>\n","            <td>😡&nbsp;</td>\n","            <td>😄&nbsp;</td>\n","            </tr>\n","            \n","\n","            <tr>\n","            <td>It is important and only fair to remember that, at the time this short was produced, a state of war existed between the United States and the Empire of Japan. Add to that the enormous ill-will that the beginning of the war created, as well as the Bataan Death March and other incidents and the only thing surprising about this short and others is that there weren't more of them. One other thing: my only problem with this short is that it seems to try to be funny, but it isn't. I'm not sure that anyone connected with it really tried to make the jokes work, or even cared. It would have been far better if they had done what Disney did with Education For Death and been totally serious. But this short gets a bad rap and shouldn't be judged out of context. The times were different then and that is an important consideration. Anyone expending energy trying to save the world from a sixty-year old cartoon needs to take a step back. As do I, expending energy defending that same cartoon. This should be available to interested parties, even if not in wide circulation. Not a nice cartoon, but sometimes life isn't nice. Recommended&nbsp;</td>\n","            <td>😄&nbsp;</td>\n","            <td>😄&nbsp;</td>\n","            </tr>\n","            \n","\n","            <tr>\n","            <td>I was bored, around 10pm, so I watched this movie. And I could not stop laughing. Everything was so ridiculous. The way the kids were acting like they were older than 11 just cracked me up. One of the kids had a ring, that supposedly killed people after 3 or so years. It gave me the impression that he wanted to be a gangster.<br /><br />It's pretty hard to take little kids seriously, especially when it has to do with eating worms. They act like everything is such a big deal, like if Billy (the main character) doesn't eat the worms then the world will end.<br /><br />This is a good movie for little kids (excluding the fact that a 5 year old says 'penis'), but not for teens or adults who don't want to waste their time.&nbsp;</td>\n","            <td>😡&nbsp;</td>\n","            <td>😡&nbsp;</td>\n","            </tr>\n","            \n","\n","            <tr>\n","            <td>When this film gets it right it really gets it right. And when it goes wrong... I'd say that a full 3/4s of the film is great. I can even isolate the bad bit. It's everything that has to do with the romance. Everything that you need to know about it is said in the first five minutes but it drags on for about 30. I'd recommend skipping that section if you can. It does nothing except explain his exile. It should have been a minor plot point quickly thrust aside. Fortunately, the period from about 0-30 and 1:00-2:19 (The End) is excellent.<br /><br />There are a number of excellent performances in this film, and an equal number of terrible ones. Just like everything else in this movie the acting is either perfect or terrible. Peter Ustinov as the slimy one-eyed slave Kaptah is perfect. It is one of his best performances, up there with his role in Spartacus. Victor Mature as the ambitious Horemheb is also perfect. Again, one of his best roles. Jean Simmons is wasted as Merit, the perfect girl in love with our hero John Carradine gives a nice supporting role as a philosophical grave robber; and Michael Wilding is excellent as Akhnaton, the idealistic pharaoh who tries to bring peace and monotheism to Egypt only to see it fall apart due to his unwillingness to fight. Now for the bad. Edmund Purdom as Sinuhe is sadly miscast. This is doubly unfortunate as he is the main character. The entire film revolves around him. He actually does rather good as the disillusioned exile and the wise old man. This is because of his sorely limited range. He doesn't seem able to put any passion into his words. This is especially apparent during the love scenes which are beyond awkward. He spends the last half of the film as an old man, a performance at which he is decent enough at. He does have the perfect voice for the character. The less said about Bella Darvi as Nefer, the treacherous Babylonian woman, the better.<br /><br />The costuming and sets are magnificent. This is the only film that I know of that attempts to depict life in Egypt that isn't overshadowed by Jews or Romans. The film takes place in the 14th Century B.C. which is before even Exodus. The only monotheists are the pharaoh Akhenaten and his followers. There is the same strong element of religious zeal that can be found in most epics, but it is done differently and it only shows up at the very end. An interesting note: by having Akhenaten followed by Horemheb as pharaoh, the film completely skips over the most famous pharaoh of all: Tutankhamen. Seems kind of a strange thing to do when using that name could increase awareness of the film.<br /><br />Be warned: this is a 1950s epic film. If you don't like that type of thing then don't expect this one to be different. It is different, but it is still an epic. I appreciate this film, and I appreciate what it did and what it tried to do. This is a film that should be better remembered than it is.&nbsp;</td>\n","            <td>😡&nbsp;</td>\n","            <td>😄&nbsp;</td>\n","            </tr>\n","            \n","</tbody>\n","</table>\n"]},"metadata":{}}]}]}