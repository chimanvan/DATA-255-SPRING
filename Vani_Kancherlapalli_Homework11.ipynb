{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4EPYWthQ7tl"
   },
   "source": [
    "Write prompts using OPENAI API keys that perform the following task and display the output:\n",
    "1. Write a chatbot prompt to iteratively create a sequence of chats on one particular topic.\n",
    "      a. Ask the bot to solve one complex math problem.\n",
    "      b. Give a PDF and website document; ask the bot to rewrite and answer questions on the given PDF and website.\n",
    "      c. At the end, ask the bot to summarize your chat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yv_LY9_PD2NQ",
    "outputId": "a089ffde-da87-481f-a07f-872283b6b6c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kFSuFSUeER4p",
    "outputId": "dedcc56d-510e-4cad-8b18-a0045cb88c26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Data 255 Spring 2024/Google Colab/Homework11\n"
     ]
    }
   ],
   "source": [
    "%cd '/content/drive/My Drive/Data 255 Spring 2024/Google Colab/Homework11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMHdxEkXEY1B"
   },
   "outputs": [],
   "source": [
    "# Install the necessary libraries\n",
    "# Openai was compatible with version 0.28\n",
    "\n",
    "# !pip install openai\n",
    "# current version is openai 1.23.6\n",
    "# !pip install python-dotenv\n",
    "# !pip uninstall openai\n",
    "# !pip install openai==0.28\n",
    "# !pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKP8gG0w5VF0"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = 'xxxx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_5jd1FZRc9V"
   },
   "source": [
    "## 1. Write a chatbot prompt to iteratively create a sequence of chats on one particular topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3UAptY3L5SLX",
    "outputId": "72dd3750-dc4f-4b29-a3ec-a6b54c96daf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Content: It is difficult to predict the exact temperature in San Jose in the year 2050 due to the many factors that can influence weather patterns and climate change. However, based on current climate change projections, it is likely that temperatures in San Jose and other regions will continue to rise. This could lead to hotter summers, more frequent heatwaves, and overall warmer conditions in the future. It is important to continue monitoring and addressing climate change in order to mitigate its impact on our communities and environment.\n"
     ]
    }
   ],
   "source": [
    "# Ask general questions to chatbot\n",
    "\n",
    "try:\n",
    "    response = openai.ChatCompletion.create(\n",
    "         # chat model\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"How hot will the weather be in San Jose in year 2050?\"}],\n",
    "        max_tokens=150\n",
    "    )\n",
    "    # access the content of the response\n",
    "    if 'choices' in response and response['choices']:\n",
    "        first_choice = response['choices'][0]\n",
    "        if 'message' in first_choice:\n",
    "            print(\"Response Content:\", first_choice['message']['content'])\n",
    "        else:\n",
    "            print(\"No message content available.\")\n",
    "    else:\n",
    "        print(\"No choices available.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-xt5ZP75mkI",
    "outputId": "0818371d-e5f8-4fa6-943f-d2a185d916f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Content: Studying for an exam with a lot of content can be overwhelming, but with some strategic planning and effective study techniques, you can maximize your chances of success. Here are some tips on how to study for an exam with a lot of content:\n",
      "\n",
      "1. Break down the content: Divide the content into smaller, manageable chunks and create a study schedule that allows you to cover each topic thoroughly. Organize your study material based on the order of importance or difficulty.\n",
      "\n",
      "2. Take notes and summarize: While studying, take notes of key concepts, formulas, definitions, and important information. Summarizing the content in your own words can help you understand and remember the material better.\n",
      "\n",
      "3. Use different study methods: Mix up your study methods to keep\n"
     ]
    }
   ],
   "source": [
    "# Ask another general question\n",
    "try:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"How to study for an exam with lot of content?\"}],\n",
    "        max_tokens=150\n",
    "    )\n",
    "    # access the content of the response\n",
    "    if 'choices' in response and response['choices']:\n",
    "        first_choice = response['choices'][0]\n",
    "        if 'message' in first_choice:\n",
    "            print(\"Response Content:\", first_choice['message']['content'])\n",
    "        else:\n",
    "            print(\"No message content available.\")\n",
    "    else:\n",
    "        print(\"No choices available.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gt13Fwlq5zdJ",
    "outputId": "ed720352-df69-4fa5-fde5-441e2c48a16c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Content: If a certain area of a topic is confusing, here are some strategies you can use to study and better understand it:\n",
      "\n",
      "1. Break it down: Break the topic into smaller, more manageable sections and focus on understanding each section before moving on to the next.\n",
      "\n",
      "2. Look for different resources: Try different textbooks, online resources, videos, or ask for help from a teacher or tutor. Sometimes a different perspective or explanation can make all the difference.\n",
      "\n",
      "3. Take notes: Write down key concepts, definitions, and explanations in your own words. This can help you organize your thoughts and reinforce your understanding of the topic.\n",
      "\n",
      "4. Practice with examples: Work on practice problems or examples related to the confusing topic. This can help you apply your knowledge and\n"
     ]
    }
   ],
   "source": [
    "# Ask additional question related to previous question\n",
    "\n",
    "try:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"How to study if a certain area of topic is confusing?\"}],\n",
    "        max_tokens=150\n",
    "    )\n",
    "\n",
    "    #  access the content of the response\n",
    "    if 'choices' in response and response['choices']:\n",
    "        first_choice = response['choices'][0]\n",
    "        if 'message' in first_choice:\n",
    "            print(\"Response Content:\", first_choice['message']['content'])\n",
    "        else:\n",
    "            print(\"No message content available.\")\n",
    "    else:\n",
    "        print(\"No choices available.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r9aJQdqY5_T2",
    "outputId": "1a07a9fb-0040-4638-efd0-c20a229dd900"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Content: There is no set rule on how long you should study before moving on to the next topic as it can vary depending on your learning style, the complexity of the material, and your level of understanding. However, it is generally recommended to study a topic until you feel comfortable and confident in your understanding of it before moving on to the next one. This may involve reviewing your notes, practicing problems, discussing the topic with classmates or instructors, and taking practice quizzes or tests. It is important to ensure that you have mastered the material before moving on to prevent gaps in your knowledge which can make it more difficult to learn new material. Ultimately, the key is to prioritize understanding and retention over simply covering a certain amount of material in a set amount of time.\n"
     ]
    }
   ],
   "source": [
    "# Ask addtional question to previous question\n",
    "try:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[{\"role\": \"user\", \"content\": \"How to study should I study before moving onto the next topic?\"}],\n",
    "        max_tokens=150\n",
    "    )\n",
    "\n",
    "    #  access the content of the response\n",
    "    if 'choices' in response and response['choices']:\n",
    "        first_choice = response['choices'][0]\n",
    "        if 'message' in first_choice:\n",
    "            print(\"Response Content:\", first_choice['message']['content'])\n",
    "        else:\n",
    "            print(\"No message content available.\")\n",
    "    else:\n",
    "        print(\"No choices available.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9429XoVSBFN"
   },
   "source": [
    "##   a. Ask the bot to solve one complex math problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tDMp4pw_1n95",
    "outputId": "cd43f4c1-1f8c-4ac6-f81a-b7d04f41b7c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Content: To solve this problem, we will need to use integration by parts. Integration by parts states that: ∫u dv = uv - ∫v du.\n",
      "\n",
      "In this case, we will let u = x^3 and dv = sin(x) * e^(-x) dx. Then we will differentiate u to get du and integrate dv to get v.\n",
      "\n",
      "Differentiating u:\n",
      "du = 3x^2 dx\n",
      "\n",
      "Integrating dv:\n",
      "To integrate sin(x) * e^(-x), we will use integration by parts again. Let u = sin(x) and dv = e^(-x) dx.\n",
      "\n",
      "Differentiating u:\n",
      "du = cos(x) dx\n",
      "\n",
      "Integrating dv:\n",
      "v = -e^(-x)\n",
      "\n",
      "Now we can use the formula for integration by parts:\n",
      "∫x^3 * sin(x) * e^(-x) dx = x^3 * (-e^(-x) * sin(x)) - ∫-e^(-x) * 3x^2 * cos(x) dx\n",
      "\n",
      "Expanding the first term:\n",
      "= -x^3 * e^(-x) * sin(x) + ∫3x^2 * e^(-x) * cos(x) dx\n",
      "\n",
      "Now we can apply integration by parts again. Let u = 3x^2 and dv = e^(-x) * cos(x) dx.\n",
      "\n",
      "Differentiating u:\n",
      "du = 6x dx\n",
      "\n",
      "Integrating dv:\n",
      "We will integrate e^(-x) * cos(x). We can differentiate cos(x) to get -sin(x) and integrate e^(-x) dx to get -e^(-x).\n",
      "\n",
      "v = -e^(-x) * cos(x)\n",
      "\n",
      "Now we can apply the formula for integration by parts:\n",
      "= -x^3 * e^(-x) * sin(x) + (-3x^2 * e^(-x) * cos(x) + ∫-6x * e^(-x) * -sin(x) dx)\n",
      "\n",
      "Expanding the second term:\n",
      "= -x^3 * e^(-x) * sin(x) + 3x^2 * e^(-x) * cos(x) + ∫6x * e^(-x) * sin(x) dx\n",
      "\n",
      "Now we have a new integral to solve:\n",
      "∫6x * e^(-x) * sin(x) dx\n",
      "\n",
      "We can apply integration by parts one more time. Let u = 6x and dv = e^(-x) * sin(x) dx.\n",
      "\n",
      "Differentiating u:\n",
      "du = 6 dx\n",
      "\n",
      "Integrating dv:\n",
      "We already know that the integral of e^(-x) * sin(x) dx will be a combination of sin(x) and cos(x) terms.\n",
      "\n",
      "v = -e^(-x) * sin(x) + e^(-x) * cos(x)\n",
      "\n",
      "Now we can use integration by parts one final time:\n",
      "= -x^3 * e^(-x) * sin(x) + 3x^2 * e^(-x) * cos(x) + (-(6x * e^(-x) * sin(x) + 6∫e^(-x) * cos(x) dx))\n",
      "\n",
      "Solving for the final integral:\n",
      "= -x^3 * e^(-x) * sin(x) + 3x^2 * e^(-x) * cos(x) - 6x * e^(-x) * sin(x) - 6 * (-e^(-x) * sin(x) + e^(-x) * cos(x))\n",
      "\n",
      "Now we can integrate e^(-x) * cos(x) and e^(-x) * sin(x) terms separately to find the final result.\n",
      "\n",
      "Therefore, after multiple iterations of integration by parts, the final result of the integral of g(x) with respect to x is:\n",
      "\n",
      "∫g(x) dx = -x^3 * e^(-x) * sin(x) + 3x^2 * e^(-x) * cos(x) - 6x * e^(-x) * sin(x) - 6 * (-e^(-x) * sin(x) + e^(-x) * cos(x)) + C\n",
      "\n",
      "where C is the constant of integration.\n",
      "Conversation History:\n",
      "{'role': 'assistant', 'content': 'To solve this problem, we will need to use integration by parts. Integration by parts states that: ∫u dv = uv - ∫v du.\\n\\nIn this case, we will let u = x^3 and dv = sin(x) * e^(-x) dx. Then we will differentiate u to get du and integrate dv to get v.\\n\\nDifferentiating u:\\ndu = 3x^2 dx\\n\\nIntegrating dv:\\nTo integrate sin(x) * e^(-x), we will use integration by parts again. Let u = sin(x) and dv = e^(-x) dx.\\n\\nDifferentiating u:\\ndu = cos(x) dx\\n\\nIntegrating dv:\\nv = -e^(-x)\\n\\nNow we can use the formula for integration by parts:\\n∫x^3 * sin(x) * e^(-x) dx = x^3 * (-e^(-x) * sin(x)) - ∫-e^(-x) * 3x^2 * cos(x) dx\\n\\nExpanding the first term:\\n= -x^3 * e^(-x) * sin(x) + ∫3x^2 * e^(-x) * cos(x) dx\\n\\nNow we can apply integration by parts again. Let u = 3x^2 and dv = e^(-x) * cos(x) dx.\\n\\nDifferentiating u:\\ndu = 6x dx\\n\\nIntegrating dv:\\nWe will integrate e^(-x) * cos(x). We can differentiate cos(x) to get -sin(x) and integrate e^(-x) dx to get -e^(-x).\\n\\nv = -e^(-x) * cos(x)\\n\\nNow we can apply the formula for integration by parts:\\n= -x^3 * e^(-x) * sin(x) + (-3x^2 * e^(-x) * cos(x) + ∫-6x * e^(-x) * -sin(x) dx)\\n\\nExpanding the second term:\\n= -x^3 * e^(-x) * sin(x) + 3x^2 * e^(-x) * cos(x) + ∫6x * e^(-x) * sin(x) dx\\n\\nNow we have a new integral to solve:\\n∫6x * e^(-x) * sin(x) dx\\n\\nWe can apply integration by parts one more time. Let u = 6x and dv = e^(-x) * sin(x) dx.\\n\\nDifferentiating u:\\ndu = 6 dx\\n\\nIntegrating dv:\\nWe already know that the integral of e^(-x) * sin(x) dx will be a combination of sin(x) and cos(x) terms.\\n\\nv = -e^(-x) * sin(x) + e^(-x) * cos(x)\\n\\nNow we can use integration by parts one final time:\\n= -x^3 * e^(-x) * sin(x) + 3x^2 * e^(-x) * cos(x) + (-(6x * e^(-x) * sin(x) + 6∫e^(-x) * cos(x) dx))\\n\\nSolving for the final integral:\\n= -x^3 * e^(-x) * sin(x) + 3x^2 * e^(-x) * cos(x) - 6x * e^(-x) * sin(x) - 6 * (-e^(-x) * sin(x) + e^(-x) * cos(x))\\n\\nNow we can integrate e^(-x) * cos(x) and e^(-x) * sin(x) terms separately to find the final result.\\n\\nTherefore, after multiple iterations of integration by parts, the final result of the integral of g(x) with respect to x is:\\n\\n∫g(x) dx = -x^3 * e^(-x) * sin(x) + 3x^2 * e^(-x) * cos(x) - 6x * e^(-x) * sin(x) - 6 * (-e^(-x) * sin(x) + e^(-x) * cos(x)) + C\\n\\nwhere C is the constant of integration.'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the conversation history\n",
    "messages_append = []\n",
    "\n",
    "try:\n",
    "    # Use the correct parameter name 'messages' for the chat completion request\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",  # Ensure the model name is correct\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Solve this complex math problem: Integrate the function g(x) = x^3 * sin(x) * e^(-x) with respect to x.\"}],\n",
    "        #max_tokens=300  # Adjust the token limit as needed\n",
    "    )\n",
    "\n",
    "    # Properly access the content of the response\n",
    "    if 'choices' in response and response['choices']:\n",
    "        first_choice = response['choices'][0]\n",
    "        if 'message' in first_choice and 'content' in first_choice.message:\n",
    "            response_content = first_choice.message['content']\n",
    "            print(\"Response Content:\", response_content)\n",
    "            # Append the response from the assistant to the conversation history\n",
    "            messages_append.append({\"role\": \"assistant\", \"content\": response_content})\n",
    "        else:\n",
    "            print(\"No message content available.\")\n",
    "            # Append a message indicating no content was available\n",
    "            messages_append.append({\"role\": \"assistant\", \"content\": \"No message content available.\"})\n",
    "    else:\n",
    "        print(\"No choices available.\")\n",
    "        # Append a message indicating no choices were available\n",
    "        messages_append.append({\"role\": \"assistant\", \"content\": \"No choices available.\"})\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "    # Append the error message to the conversation history\n",
    "    messages_append.append({\"role\": \"assistant\", \"content\": f\"An error occurred: {str(e)}\"})\n",
    "\n",
    "# Optionally, print the entire conversation history to review\n",
    "print(\"Conversation History:\")\n",
    "for message in messages_append:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-4Z3sI9SF-o"
   },
   "source": [
    "##  b. Give a PDF and website document; ask the bot to rewrite and answer questions on the given PDF and website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-_WZkKavhyx",
    "outputId": "1cea7e71-b72b-43d3-add0-3ea215d1f5c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: The text provides an overview of the CMPE 258 course on Deep Learning, including prerequisites and content such as the distinction between Deep Learning and Machine Learning, the history of neural networks, biological inspiration for artificial neurons, and concepts like backpropagation for training. It also mentions examples of applications like IBM Deep Blue, IBM Watson, AlphaGo, and GPT models. Additionally, the text covers the basics of Deep Learning, including neural networks, and highlights its use in fields like Image Classification, Deep Reinforcement Learning, and Autonomous Robots.\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = ''\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "              # Concatenate text of each page\n",
    "                text += page_text\n",
    "    return text\n",
    "\n",
    "# Specify the path to your PDF file\n",
    "pdf_path = '00-introduction.dnn.pdf'\n",
    "\n",
    "# Call the function to extract text\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Print the extracted text to see the contents\n",
    "#print(extracted_text)\n",
    "\n",
    "# Prepare the message for the API\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Summarize the text: {extracted_text}\"}\n",
    "]\n",
    "\n",
    "try:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=messages,\n",
    "        #max_tokens=150\n",
    "    )\n",
    "    # Extract the response content directly\n",
    "    response_content = response.choices[0].message['content']\n",
    "    print(\"Summary:\", response_content)\n",
    "    # Append the response from the assistant to the conversation history\n",
    "    messages_append.append({\"role\": \"assistant\", \"content\": response_content})\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Uvjj0mNEYTp",
    "outputId": "f53ad7d7-486f-43da-8d0b-ae89e303ce7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: The website page is currently experiencing temporary issues with delayed market data. It mentions various topics such as lower inflation impacting President Biden's reelection bid, Elon Musk's ambitions for Tesla, skepticism on Tesla's focus on next-gen products, and criticism following Tesla's first-quarter earnings. The page also discusses homebuyer demand, mortgage rates, retiree savings, investment opportunities like Newmont, tax relief programs like the IRS Fresh Start Program, and insights from business leaders like Walmart's CEO. Additionally, it touches on political news related to President Trump's aides planning to oust the Federal Reserve chairman.\n"
     ]
    }
   ],
   "source": [
    "# on a webpage\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_website_content(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # extract all paragraph texts from the webpage\n",
    "    paragraphs = soup.find_all('p')\n",
    "    text = ' '.join([p.get_text() for p in paragraphs])\n",
    "    return text\n",
    "\n",
    "#  website to analyze\n",
    "url = 'https://finance.yahoo.com/'\n",
    "website_content = fetch_website_content(url)\n",
    "#print(website_content)\n",
    "\n",
    "# Prepare the message for the API\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Summarize the website page: {website_content}\"}\n",
    "]\n",
    "\n",
    "try:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=messages,\n",
    "        #max_tokens=150  # Adjusted to allow for a potentially verbose explanation\n",
    "    )\n",
    "    # Extract the response content directly\n",
    "    response_content = response.choices[0].message['content']\n",
    "    print(\"Summary:\", response_content)\n",
    "    # Append the response from the assistant to the conversation history\n",
    "    messages_append.append({\"role\": \"assistant\", \"content\": response_content})\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyOYG3_eSejG"
   },
   "source": [
    "##   c. At the end, ask the bot to summarize your chat.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "vu-QKIUY2F3j"
   },
   "outputs": [],
   "source": [
    "# Prepare the entire conversation for summarization\n",
    "conversation_text = \" \".join([msg[\"content\"] for msg in messages_append])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9xqI-sjL2Fzi",
    "outputId": "4d0a0918-6ae2-4384-b7e1-3950f625a250"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation Summary: The conversation outlines the process of using integration by parts to solve a math problem involving multiple iterations of integration by parts. Additionally, it provides a summary of topics discussed on a webpage, including the CMPE 258 Deep Learning course, market data delays, financial and investment news, political news related to President Biden and President Trump, and insights from various business leaders such as Walmart's CEO and Elon Musk.\n"
     ]
    }
   ],
   "source": [
    "# Ask the AI to summarize the conversation\n",
    "try:\n",
    "    summary_response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"Please summarize this conversation:\"},\n",
    "                  {\"role\": \"user\", \"content\": conversation_text}],\n",
    "        #max_tokens=150\n",
    "    )\n",
    "    if 'choices' in summary_response and summary_response.choices:\n",
    "        summary_content = summary_response.choices[0].message['content']\n",
    "        print(\"Conversation Summary:\", summary_content)\n",
    "    else:\n",
    "        print(\"No valid summary received.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred while summarizing:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
